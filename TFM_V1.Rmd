---
title: "CHILD MORTALITY RATE"
author: "María Perea"
date: "Septiembre/2020"
output: html_document
---
`

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```



```{r}
library(tidyverse)
library(devtools)
library(dplyr)    
library(ggplot2)
library(broom)
library(readr)
library(pastecs)
library(tidyr)   
library(caret)
library(leaps)
library(randomForest)

```


#### Importando fichero __"Mortality_rate_Newborn_Child.csv"__
1. Se importa fichero con el indicador a estimar. 
2. Selección y cambio de nombre en columnas.
3. Creando tabla de Wide a Longer.
4. Verificando con *glimpse* la importación correcta y con *unique* los valores únicos del fichero.
```{r}
Rate_Child_all<-read.csv("Mortality_rate_Newborn_Child.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Rate_Child<-Rate_Child_all[ ,c(1,31:59)]
colnames(Rate_Child)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010","2009","2008","2007","2006","2005","2004","2003","2002","2001","2000","1999","1998","1997","1996","1995","1994","1993","1992","1991","1990")

Rate_Child <- Rate_Child %>%
  pivot_longer(cols=`2018`:`1990`,
               names_to="year",
               values_to = "Rate_Mort_Child",
               names_ptypes = list(year=integer()))
glimpse(Rate_Child)
unique(Rate_Child$Who_Region)
unique(Rate_Child$year)
```

#### Análisis indicador Rate_Mort_Child
1. Pivotando tabla de Longer a Wide (Regiones en columnas)
2. Se aplica función *stat.desc* para obtener métricas descriptiva de la tabla por **Who_Región**
```{r}
Rate_Child_wide <- Rate_Child %>%
  pivot_wider(names_from=Who_Region, 
              values_from=Rate_Mort_Child)

stat_wide<-stat.desc(Rate_Child_wide,norm = TRUE)
stat_wide<-round(stat_wide,2)
stat_wide

```

#### Gráficos __"Rate_Mort_Child"__
1. Gráfico de cajas por "Who_Región"
2. Evolutivo por "Who_Región"

```{r}
ggplot(data=Rate_Child,aes(x=Who_Region,y=Rate_Mort_Child))+
  geom_boxplot(aes(fill=Who_Region)) +
  ggtitle("Under-five mortality rate 
*years: 1990-2017*
          (probability of dying by age 5 per 1000 live births)")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic"))+
  theme(axis.text.x=element_text(angle=90, hjust=1))+
  ylab("per 1000 live births")



ggplot(data=Rate_Child,aes(x=year,y=Rate_Mort_Child))+
  geom_point(aes(col=Who_Region))+
  ggtitle("Evolution *Under-five mortality rate*
          (probability of dying by age 5 per 1000 live births)
*1990-2017*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic"))
```


#### Importando fichero __"International_Health_Regulations.csv""__
1. Contiene 13 indicadores de la Regulación Internacional de Salud(Encuestas)
2. Se importa el fichero seleccionando las columnas de cada indicador
3. Pivotando cada tabla de Wide a Longer

```{r}

Int_Health_Regulat<-read.csv("International_Health_Regulations.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)

#### Legislation
Int_Health_Regulat_Legislation<-Int_Health_Regulat[ ,c(1:9)]
colnames(Int_Health_Regulat_Legislation)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Legislation <- Int_Health_Regulat_Legislation %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Legislation",
               names_ptypes = list(year=integer()))

#### Coordination
Int_Health_Regulat_Coordination<-Int_Health_Regulat[ ,c(1,10:17)]
colnames(Int_Health_Regulat_Coordination)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Coordination<- Int_Health_Regulat_Coordination %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Coordination",
               names_ptypes = list(year=integer()))

#### Surveillance
Int_Health_Regulat_Surveillance<-Int_Health_Regulat[ ,c(1,18:25)]                                          
colnames(Int_Health_Regulat_Surveillance)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Surveillance<- Int_Health_Regulat_Surveillance %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Surveillance",
               names_ptypes = list(year=integer()))
#### Response
Int_Health_Regulat_Response<-Int_Health_Regulat[ ,c(1,26:33)]
colnames(Int_Health_Regulat_Response)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Response<- Int_Health_Regulat_Response %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Response",
               names_ptypes = list(year=integer()))
#### Preparedness
Int_Health_Regulat_Preparedness<-Int_Health_Regulat[ ,c(1,34:41)]
colnames(Int_Health_Regulat_Preparedness)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Preparedness<- Int_Health_Regulat_Preparedness %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Preparedness",
               names_ptypes = list(year=integer()))
 
#### Risk_communication
Int_Health_Regulat_Risk_communication<-Int_Health_Regulat[ ,c(1,42:49)]
colnames(Int_Health_Regulat_Risk_communication)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Risk_communication<- Int_Health_Regulat_Risk_communication %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Risk_communication",
               names_ptypes = list(year=integer()))

#### Human_resources
Int_Health_Regulat_Human_resources<-Int_Health_Regulat[ ,c(1,50:57)]
colnames(Int_Health_Regulat_Human_resources)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Human_resources<- Int_Health_Regulat_Human_resources %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Human_resources",
               names_ptypes = list(year=integer()))

#### Laboratory
Int_Health_Regulat_Laboratory<-Int_Health_Regulat[ ,c(1,58:65)]
colnames(Int_Health_Regulat_Laboratory)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Laboratory<- Int_Health_Regulat_Laboratory %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Laboratory",
               names_ptypes = list(year=integer()))
#### Points_entry
Int_Health_Regulat_Points_entry<-Int_Health_Regulat[ ,c(1,66:73)]
colnames(Int_Health_Regulat_Points_entry)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Points_entry<- Int_Health_Regulat_Points_entry %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Points_entry",
               names_ptypes = list(year=integer()))
#### Zoonosis
Int_Health_Regulat_Zoonosis<-Int_Health_Regulat[ ,c(1,74:81)]
colnames(Int_Health_Regulat_Zoonosis)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Zoonosis<- Int_Health_Regulat_Zoonosis %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Zoonosis",
               names_ptypes = list(year=integer()))
#### Food_safety
Int_Health_Regulat_Food_safety<-Int_Health_Regulat[ ,c(1,82:89)]
colnames(Int_Health_Regulat_Food_safety)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Food_safety<- Int_Health_Regulat_Food_safety %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Food_safety",
               names_ptypes = list(year=integer()))
#### Chemical
Int_Health_Regulat_Chemical<-Int_Health_Regulat[ ,c(1,90:97)]
colnames(Int_Health_Regulat_Chemical)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Chemical<- Int_Health_Regulat_Chemical %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Chemical",
               names_ptypes = list(year=integer()))

#### Radionuclear
Int_Health_Regulat_Radionuclear<-Int_Health_Regulat[ ,c(1,98:105)]
colnames(Int_Health_Regulat_Radionuclear)<-c("Who_Region","2017","2016","2015","2014","2013","2012","2011","2010")
Int_Health_Regulat_Radionuclear<- Int_Health_Regulat_Radionuclear %>%
  pivot_longer(cols=`2017`:`2010`,
               names_to="year",
               values_to = "Radionuclear",
               names_ptypes = list(year=integer()))
```

#### Fusionando con *merge* los 13 indicadores. 
1. Análisis de la tabla con *glimpse*, *unique* and *stat.desc*

```{r}
m1<-Reduce(function(...) merge(..., all=T), list(Int_Health_Regulat_Legislation,
                                                 Int_Health_Regulat_Coordination,
                                                 Int_Health_Regulat_Surveillance,
                                                 Int_Health_Regulat_Response,
                                                 Int_Health_Regulat_Preparedness,
                                                 Int_Health_Regulat_Risk_communication,
                                                 Int_Health_Regulat_Human_resources,
                                                 Int_Health_Regulat_Laboratory,
                                                 Int_Health_Regulat_Points_entry,
                                                 Int_Health_Regulat_Zoonosis,
                                                 Int_Health_Regulat_Food_safety,
                                                 Int_Health_Regulat_Chemical,
                                                 Int_Health_Regulat_Radionuclear))

glimpse(m1)
unique(m1$Who_Region)
unique(m1$year)
m1_num<-select_if(m1,is.numeric)
stat_m1<-stat.desc(m1_num)
stat_m1<-round(stat_m1,0)
stat_m1


```

#### Fusionando "indicador principal" con indicadores "International_Health_Regulation" 
1. Se decide excluir "Global" del indicador principal, porque en el resto de indicadores sólo hay datos para dos años
2. Por tanto, nos quedaríamos con 7 años de evolutivo (2010-2017)
```{r}
Rate_Child_new<-Rate_Child %>% filter(Who_Region != "Global")
m2<-Reduce(function(...) merge (..., all=F), list(Rate_Child_new,m1))
glimpse(m2)
unique(m2$Who_Region)
unique(m2$year)
```
#### Importando 12 ficheros con los "Ratios de Mortalidad por CAUSA (<5 años)"
1. Sólo nos interesa la variable (0-4 years)
2. Se homogeiniza valores de "Who_Region"
3. Verificando con *glimpse* y *unique* la importación correcta
```{r}
#### Asphyxia
Mort_Asphyxia_rate<-read.csv("MORT_Asphyxia_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Asphyxia_rate<-Mort_Asphyxia_rate[ ,c(1:2,5)]
colnames(Mort_Asphyxia_rate)<-c("Who_Region","year","Mort_Asphyxia_rate")

Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "European Region"]<-"Europe"
Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Asphyxia_rate$Who_Region[Mort_Asphyxia_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Asphyxia_rate)
unique(Mort_Asphyxia_rate$Who_Region)

####  Congenital_anom
Mort_Congenital_rate<-read.csv("MORT_Congenital_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Congenital_rate<-Mort_Congenital_rate[ ,c(1:2,5)]
colnames(Mort_Congenital_rate)<-c("Who_Region","year","Mort_Congenital_rate")

Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "European Region"]<-"Europe"
Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Congenital_rate$Who_Region[Mort_Congenital_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Congenital_rate)
unique(Mort_Congenital_rate$Who_Region)

####  Diarrhoeal_diseases

Mort_Diarrhoeal_diseases_rate<-read.csv("MORT_Diarre_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Diarrhoeal_diseases_rate<-Mort_Diarrhoeal_diseases_rate[ ,c(1:2,5)]
colnames(Mort_Diarrhoeal_diseases_rate)<-c("Who_Region","year","Mort_Diarrhoeal_rate")

Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "European Region"]<-"Europe"
Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Diarrhoeal_diseases_rate$Who_Region[Mort_Diarrhoeal_diseases_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Diarrhoeal_diseases_rate)
unique(Mort_Diarrhoeal_diseases_rate$Who_Region)


####  MORT_HIVAIDS_rate

Mort_HIVAIDS_rate<-read.csv("MORT_HIVAIDS_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_HIVAIDS_rate<-Mort_HIVAIDS_rate[ ,c(1:2,5)]
colnames(Mort_HIVAIDS_rate)<-c("Who_Region","year","Mort_HIVAIDS_dis_rate")

Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "European Region"]<-"Europe"
Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_HIVAIDS_rate$Who_Region[Mort_HIVAIDS_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_HIVAIDS_rate)
unique(Mort_HIVAIDS_rate$Who_Region)

#### MORT_Malaria_rate

Mort_Malaria_rate<-read.csv("MORT_Malaria_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Malaria_rate<-Mort_Malaria_rate[ ,c(1:2,5)]
colnames(Mort_Malaria_rate)<-c("Who_Region","year","Mort_Malaria_rate")

Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "European Region"]<-"Europe"
Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Malaria_rate$Who_Region[Mort_Malaria_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Malaria_rate)
unique(Mort_Malaria_rate$Who_Region)

#### MORT_Measles_rate

Mort_Measles_rate<-read.csv("MORT_Measles_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Measles_rate<-Mort_Measles_rate[ ,c(1:2,5)]
colnames(Mort_Measles_rate)<-c("Who_Region","year","Mort_Measles_rate")

Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "European Region"]<-"Europe"
Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Measles_rate$Who_Region[Mort_Measles_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Measles_rate)
unique(Mort_Measles_rate$Who_Region)

#### MORT_Meningitis_rate

Mort_Meningitis_rate<-read.csv("MORT_Meningitis_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Meningitis_rate<-Mort_Meningitis_rate[ ,c(1:2,5)]
colnames(Mort_Meningitis_rate)<-c("Who_Region","year","Mort_Meningitis_rate")

Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "European Region"]<-"Europe"
Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Meningitis_rate$Who_Region[Mort_Meningitis_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Meningitis_rate)
unique(Mort_Meningitis_rate$Who_Region)

#### MORT_Other_rate

Mort_Other_rate<-read.csv("MORT_Other_Nutri_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Other_rate<-Mort_Other_rate[ ,c(1:2,5)]
colnames(Mort_Other_rate)<-c("Who_Region","year","Mort_Other_rate")

Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "European Region"]<-"Europe"
Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Other_rate$Who_Region[Mort_Other_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Other_rate)
unique(Mort_Other_rate$Who_Region)


#### MORT_Prematurity_rate

Mort_Prematurity_rate<-read.csv("MORT_Prematurity_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Prematurity_rate<-Mort_Prematurity_rate[ ,c(1:2,5)]
colnames(Mort_Prematurity_rate)<-c("Who_Region","year","Mort_Prematurity_rate")

Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "European Region"]<-"Europe"
Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Prematurity_rate$Who_Region[Mort_Prematurity_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Prematurity_rate)
unique(Mort_Prematurity_rate$Who_Region)

#### MORT_Respiratory_rate

Mort_Respiratory_rate<-read.csv("MORT_Respiratory_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Respiratory_rate<-Mort_Respiratory_rate[ ,c(1:2,5)]
colnames(Mort_Respiratory_rate)<-c("Who_Region","year","Mort_Respiratory_rate")

Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "European Region"]<-"Europe"
Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Respiratory_rate$Who_Region[Mort_Respiratory_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Respiratory_rate)
unique(Mort_Respiratory_rate$Who_Region)

#### MORT_Sepsis_rate

Mort_Sepsis_rate<-read.csv("MORT_Sepsis_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Sepsis_rate<-Mort_Sepsis_rate[ ,c(1:2,5)]
colnames(Mort_Sepsis_rate)<-c("Who_Region","year","Mort_Sepsis_rate")

Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "European Region"]<-"Europe"
Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Sepsis_rate$Who_Region[Mort_Sepsis_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Sepsis_rate)
unique(Mort_Sepsis_rate$Who_Region)

#### MORT_Tetanos_rate

Mort_Tetanos_rate<-read.csv("MORT_Tetanos_rate.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 2)
Mort_Tetanos_rate<-Mort_Tetanos_rate[ ,c(1:2,5)]
colnames(Mort_Tetanos_rate)<-c("Who_Region","year","Mort_Tetanos_rate")

Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "Africa Region"]<-"Africa" 
Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "Region of the Americas"]<-"Americas"
Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "Eastern Mediterranean Region"]<-"Eastern Mediterranean"
Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "European Region"]<-"Europe"
Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "South-East Asia Region"]<-"South-East Asia"
Mort_Tetanos_rate$Who_Region[Mort_Tetanos_rate$Who_Region == "Western Pacific Region"]<-"Western Pacific"

glimpse(Mort_Tetanos_rate)
unique(Mort_Tetanos_rate$Who_Region)

```



#### Fusionando con *merge* los 12 indicadores de  "Causas de Mortalidad Infantil(Rate)"
1. Análisis de la tabla con *glimpse*, *unique* and *stat.desc*

```{r}
m3<-Reduce(function(...) merge(..., all=T), list(Mort_Asphyxia_rate,
                                                 Mort_Congenital_rate,
                                                 Mort_Diarrhoeal_diseases_rate,
                                                 Mort_HIVAIDS_rate,
                                                 Mort_Malaria_rate,
                                                 Mort_Measles_rate,
                                                 Mort_Meningitis_rate,
                                                 Mort_Other_rate,
                                                 Mort_Respiratory_rate,
                                                 Mort_Prematurity_rate,
                                                 Mort_Sepsis_rate,
                                                 Mort_Tetanos_rate))

glimpse(m3)
unique(m3$Who_Region)
unique(m3$year)
m3_num<-select_if(m3,is.numeric)
stat_m3<-stat.desc(m3_num)
stat_m3<-round(stat_m3,0)
stat_m3
```


#### Fusionando "tabla principal acumulado" con la tabla de indicadores "Mort_Cause_Rate"
1. Comprobando resultados con *glimpse* y *unique*
```{r}
m4<-Reduce(function(...) merge (..., all=F), list(m2,m3))
glimpse(m4)
unique(m4$Who_Region)
unique(m4$year)

```


#### Importando ficheros con los indicadores "Immunization coverage"
1. Se pivota de wide a longer
2. Son nueve indicadores en total. 
```{r}
#### Inm_BCG.csv
Inm_BCG<-read.csv("Inm_BCG.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_BCG<-Inm_BCG[ ,c(1:10)]
colnames(Inm_BCG)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_BCG<- Inm_BCG %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_BCG_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_BCG)
unique(Inm_BCG$Who_Region)
unique(Inm_BCG$year)

#### Inm_DTP3.csv
Inm_DTP3<-read.csv("Inm_DTP3.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_DTP3<-Inm_DTP3[ ,c(1:10)]
colnames(Inm_DTP3)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_DTP3<- Inm_DTP3 %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_DTP3_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_DTP3)
unique(Inm_DTP3$Who_Region)
unique(Inm_DTP3$year)


#### Inm_Hib3.csv
Inm_Hib3<-read.csv("Inm_Hib3.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_Hib3<-Inm_Hib3[ ,c(1:10)]
colnames(Inm_Hib3)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_Hib3<- Inm_Hib3 %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_Hib3_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_Hib3)
unique(Inm_Hib3$Who_Region)
unique(Inm_Hib3$year)

#### Inm_HepB3.csv
Inm_HepB3<-read.csv("Inm_HepB3.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_HepB3<-Inm_HepB3[ ,c(1:10)]
colnames(Inm_HepB3)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_HepB3<- Inm_HepB3 %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_HepB3_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_HepB3)
unique(Inm_HepB3$Who_Region)
unique(Inm_HepB3$year)

#### Inm_MCV1_1st.csv
Inm_MCV1_1st<-read.csv("Inm_MCV1_1st.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_MCV1_1st<-Inm_MCV1_1st[ ,c(1:10)]
colnames(Inm_MCV1_1st)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_MCV1_1st<- Inm_MCV1_1st %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_MCV1_1st_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_MCV1_1st)
unique(Inm_MCV1_1st$Who_Region)
unique(Inm_MCV1_1st$year)

#### Inm_MCV2_2nd.csv
Inm_MCV2_2nd<-read.csv("Inm_MCV2_2nd.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_MCV2_2nd<-Inm_MCV2_2nd[ ,c(1:10)]
colnames(Inm_MCV2_2nd)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_MCV2_2nd<- Inm_MCV2_2nd %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_MCV2_2nd_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_MCV2_2nd)
unique(Inm_MCV2_2nd$Who_Region)
unique(Inm_MCV2_2nd$year)

#### Inm_PCV3.csv
Inm_PCV3<-read.csv("Inm_PCV3.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_PCV3<-Inm_PCV3[ ,c(1:10)]
colnames(Inm_PCV3)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_PCV3<- Inm_PCV3 %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_PCV3_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_PCV3)
unique(Inm_PCV3$Who_Region)
unique(Inm_PCV3$year)

#### Inm_Pol3.csv
Inm_Pol3<-read.csv("Inm_Pol3.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_Pol3<-Inm_Pol3[ ,c(1:10)]
colnames(Inm_Pol3)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_Pol3<- Inm_Pol3 %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_Pol3_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_Pol3)
unique(Inm_Pol3$Who_Region)
unique(Inm_Pol3$year)

#### Inm_ROTAC.csv
Inm_ROTAC<-read.csv("Inm_ROTAC.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
Inm_ROTAC<-Inm_ROTAC[ ,c(1:10)]
colnames(Inm_ROTAC)<-c("Who_Region","2018","2017","2016","2015","2014","2013","2012","2011","2010")

Inm_ROTAC<- Inm_ROTAC %>%
  pivot_longer(cols=`2018`:`2010`,
               names_to="year",
               values_to = "Inm_ROTAC_coverage",
               names_ptypes = list(year=integer()))

glimpse(Inm_ROTAC)
unique(Inm_ROTAC$Who_Region)
unique(Inm_ROTAC$year)
```


#### Fusionando tablas con los indicadores "Inm_Cause_Rate"

```{r}
m5<-Reduce(function(...) merge(..., all=T), list(Inm_BCG,
                                                 Inm_DTP3,
                                                 Inm_Hib3,
                                                 Inm_HepB3,
                                                 Inm_MCV1_1st,
                                                 Inm_MCV2_2nd,
                                                 Inm_PCV3,
                                                 Inm_Pol3,
                                                 Inm_ROTAC))

glimpse(m5)
unique(m5$Who_Region)
unique(m5$year)
m5_num<-select_if(m5,is.numeric)
stat_m5<-stat.desc(m5_num)
stat_m5<-round(stat_m5,0)
stat_m5
```

#### Merge de la tabla principal con la tabla "Inm_Cause_Rate"

```{r}
m6<-Reduce(function(...) merge (..., all=F), list(m4,m5))
glimpse(m6)
unique(m6$Who_Region)
unique(m6$year)
```


#### Importando ficheros con los indicadores __"Child Malnutrition"__
1. Son dos indicadores, las variables contienen el valor y el intervalo de confianza, es de tipo carácter, se extrae el valor y se convierte a numérico
2. En el indicador "ANAEMIA_Children5" se tiene que pivotar la tabla de wide a longer

```{r}
#### Weight_Low_birth
A_Weight_Low_birth<-read.csv("A_Weight_Low_birth.csv",sep=",",header = TRUE,stringsAsFactors = FALSE)
A_Weight_Low_birth<-A_Weight_Low_birth[,c(1:2,4)]
colnames(A_Weight_Low_birth)<-c("Who_Region","year","Low_birth_weight")
A_Weight_Low_birth$Low_birth_weight<-substr(A_Weight_Low_birth$Low_birth_weight,1,4)
A_Weight_Low_birth$Low_birth_weight<-as.numeric(A_Weight_Low_birth$Low_birth_weight)
glimpse(A_Weight_Low_birth)
unique(A_Weight_Low_birth$Who_Region)
unique(A_Weight_Low_birth$year)


#### ANAEMIA_Children5
ANAEMIA_Children5<-read.csv("ANAEMIA_Children5.csv",sep=",",header = TRUE,stringsAsFactors = FALSE,skip = 1)
ANAEMIA_Children5<-ANAEMIA_Children5[,c(1:8)]
colnames(ANAEMIA_Children5)<-c("Who_Region","2016","2015","2014","2013","2012","2011","2010")

ANAEMIA_Children5<- ANAEMIA_Children5 %>%
  pivot_longer(cols=`2016`:`2010`,
               names_to="year",
               values_to = "ANAEMIA_Children5",
               names_ptypes = list(year=integer()))

ANAEMIA_Children5$ANAEMIA_Children5<-substr(ANAEMIA_Children5$ANAEMIA_Children5,1,4)
ANAEMIA_Children5$ANAEMIA_Children5<-as.numeric(ANAEMIA_Children5$ANAEMIA_Children5)
glimpse(ANAEMIA_Children5)
unique(ANAEMIA_Children5$Who_Region)
unique(ANAEMIA_Children5$year)
```

#### Para el indicador "ANAEMIA_Children5" falta el año 2017, 
1. Se genera un ggplot para ver evolutivo.
2. Se estima por regresión lineal "lm" para cada Who_Region.
```{r}
ggplot(data=ANAEMIA_Children5,aes(x=year,y=ANAEMIA_Children5))+
  geom_point(aes(col=Who_Region))
```

#### Se genera un "Lineal model" para cada Who_Region para el indicador "ANAEMIA_Children5"
1. Todos los "lm" superan de un 0.96 de R2, excepto Europa y América que están entorno al 0.7.
2. Se generan las predicciones con los modelos lineales.
```{r}
Anaemia_Africa<-ANAEMIA_Children5 %>% filter(Who_Region== 'Africa')
Anaemia_Americas<-ANAEMIA_Children5 %>% filter(Who_Region== 'Americas')
Anaemia_South_East_Asia<-ANAEMIA_Children5 %>% filter(Who_Region== "South-East Asia")
Anaemia_Europe<-ANAEMIA_Children5 %>% filter(Who_Region== 'Europe')
Anaemia_Eastern_Mediterranean<-ANAEMIA_Children5 %>% filter(Who_Region== 'Eastern Mediterranean')
Anaemia_Western_Pacific<-ANAEMIA_Children5 %>% filter(Who_Region== 'Western Pacific')

model_Africa<-lm(ANAEMIA_Children5~year,data=Anaemia_Africa)
model_Americas<-lm(ANAEMIA_Children5~year,data=Anaemia_Americas)
model_South_East_Asia<-lm(ANAEMIA_Children5~year,data=Anaemia_South_East_Asia)
model_Europe<-lm(ANAEMIA_Children5~year,data=Anaemia_Europe)
model_Eastern_Mediterranean<-lm(ANAEMIA_Children5~year,data=Anaemia_Eastern_Mediterranean)
model_Western_Pacific<-lm(ANAEMIA_Children5~year,data=Anaemia_Western_Pacific)

summary(model_Africa)
summary(model_Americas)
summary(model_South_East_Asia)
summary(model_Europe)
summary(model_Eastern_Mediterranean)
summary(model_Western_Pacific)

newdata<-data.frame(year=c(2017))
pred_Africa<-model_Africa %>% predict(newdata)
pred_Americas<-model_Americas %>% predict(newdata)
pred_South<-model_South_East_Asia %>% predict(newdata)
pred_Europe<-model_Europe %>% predict(newdata)
pred_Eastern<-model_Eastern_Mediterranean %>% predict(newdata)
pred_Western<-model_Western_Pacific %>% predict(newdata)

pred_2017_Anaemia<-data.frame(Who_Region=c("Africa","Americas","South-East Asia","Europe","Eastern Mediterranean","Western Pacific"),
                year=rep(2017,6),
                ANAEMIA_Children5=c(pred_Africa,pred_Americas ,pred_South ,pred_Europe ,pred_Eastern ,pred_Western))
         
pred_2017_Anaemia$ANAEMIA_Children5<-round(pred_2017_Anaemia$ANAEMIA_Children5,1)   
pred_2017_Anaemia$Who_Region<-as.character(pred_2017_Anaemia$Who_Region)
glimpse(pred_2017_Anaemia)
ANAEMIA_Children5<-rbind(ANAEMIA_Children5,pred_2017_Anaemia)
unique(ANAEMIA_Children5$year)

```

#### Para el indicador __"Weight_Low_birth"__ falta el año **2016&2017**
1. Se genera un ggplot para ver evolutivo
2. Se estima por regresión lineal para cada Who_Region.

```{r}
ggplot(data=A_Weight_Low_birth,aes(x=year,y=Low_birth_weight))+
  geom_point(aes(col=Who_Region))
```

#### Se genera un "Lineal model" para cada Who_Region, con la predicción.
1. Todos los "lm" superan de R2 un 0.95, excepto América que tiene un R2 muy bajo "0.01", porque sus valores tienen poca variabilidad. La estimación que hace es buena porque los valores son muy constantes.

```{r}
Low_birth_weight_Africa<-A_Weight_Low_birth %>% filter(Who_Region== 'Africa')
Low_birth_weight_Americas<-A_Weight_Low_birth %>% filter(Who_Region== 'Americas')
Low_birth_weight_South_East_Asia<-A_Weight_Low_birth %>% filter(Who_Region== "South-East Asia")
Low_birth_weight_Europe<-A_Weight_Low_birth %>% filter(Who_Region== 'Europe')
Low_birth_weight_Eastern_Mediterranean<-A_Weight_Low_birth %>% filter(Who_Region== 'Eastern Mediterranean')
Low_birth_weight_Western_Pacific<-A_Weight_Low_birth %>% filter(Who_Region== 'Western Pacific')

model_Africa<-lm(Low_birth_weight~year,data=Low_birth_weight_Africa)
model_Americas<-lm(Low_birth_weight~year,data=Low_birth_weight_Americas)
model_South_East_Asia<-lm(Low_birth_weight~year,data=Low_birth_weight_South_East_Asia)
model_Europe<-lm(Low_birth_weight~year,data=Low_birth_weight_Europe)
model_Eastern_Mediterranean<-lm(Low_birth_weight~year,data=Low_birth_weight_Eastern_Mediterranean)
model_Western_Pacific<-lm(Low_birth_weight~year,data=Low_birth_weight_Western_Pacific)

summary(model_Africa)
summary(model_Americas)
summary(model_South_East_Asia)
summary(model_Europe)
summary(model_Eastern_Mediterranean)
summary(model_Western_Pacific)

newdata<-data.frame(year=c(2016,2017))
pred_Africa<-model_Africa %>% predict(newdata)
pred_Americas<-model_Americas %>% predict(newdata)
pred_South<-model_South_East_Asia %>% predict(newdata)
pred_Europe<-model_Europe %>% predict(newdata)
pred_Eastern<-model_Eastern_Mediterranean %>% predict(newdata)
pred_Western<-model_Western_Pacific %>% predict(newdata)

pred_2016_17_Low_birth_weight<-data.frame(Who_Region=c(rep("Africa",2),rep("Americas",2),rep("South-East Asia",2),rep("Europe",2),rep("Eastern Mediterranean",2),rep("Western Pacific",2)),
                              year=c(rep(2016:2017,6)),
                              Low_birth_weight=c(pred_Africa,pred_Americas ,pred_South ,pred_Europe ,pred_Eastern ,pred_Western))

pred_2016_17_Low_birth_weight$Low_birth_weight<-round(pred_2016_17_Low_birth_weight$Low_birth_weight,1)
pred_2016_17_Low_birth_weight$Who_Region<-as.character(pred_2016_17_Low_birth_weight$Who_Region)
glimpse(pred_2016_17_Low_birth_weight)

A_Weight_Low_birth<-rbind(A_Weight_Low_birth,pred_2016_17_Low_birth_weight)
```


#### Se actualizan al dataset las estimaciones de estos indicadores.
```{r}
m7<-Reduce(function(...) merge (..., all.x=TRUE), list(m6,ANAEMIA_Children5,A_Weight_Low_birth))
glimpse(m7)
unique(m7$Who_Region)
unique(m7$year)

```



#### Analizando valores nulos y NAs del dataset "m7" montado hasta ahora.
1. Con la función *stat.desc* y las métricas **nbr.null** y **nbr.na**
2. Se identifican NAs en los siguientes indicadores: **Inm_PCV3_coverage** & **Inm_ROTAC_coverage**.
3. Y valores nulos en Mort_HIVAIDS_dis_rate, Mort_Malaria_rate,Mort_Measles_rate y Mort_Tetanos_rate
```{r}
m7_num<-select_if(m7,is.numeric)
stat_m7<-stat.desc(m7_num)
stat_m7<-round(stat_m7,1)

stat_m7[,(stat_m7["nbr.null",]>0)] 
stat_m7[,(stat_m7["nbr.na",]>0)] 

```

#### Analizando los NAs en **Inm_PCV3_coverage** & **Inm_ROTAC_coverage**
1. Se identifican las  regiones dónde están los NAs y se analiza cuál es la mejor estimación.
2. Después de visualizar gráfico con evolutivo, se va a estimar 2010 a 2014 por regresión lineal para South_East_Asia, pero el valor va a ser negativo. Para 2014 sale 0, se ponen todos los NAs a 0.
3. Analizando "Eastern Mediterranean" y "South-East Asia" para el indicador "Inm_ROTAC", ocurre lo mismo que en el anterior, por tanto, se ponen los NAs a 0 también.

```{r}
m7$Who_Region[which(is.na(m7$Inm_PCV3_coverage))]
m7$Who_Region[which(is.na(m7$Inm_ROTAC_coverage))]

Inm_PCV3_South_East_Asia<-Inm_PCV3 %>% filter(Inm_PCV3$Who_Region=="South-East Asia" & year>='2015')

ggplot(data=Inm_PCV3_South_East_Asia,aes(x=year,y=Inm_PCV3_coverage))+
  geom_point()  


model_3<-lm(Inm_PCV3_coverage~year, data =Inm_PCV3_South_East_Asia )
summary(model_3)
new_data<-data.frame(year=c(2010,2011,2012,2013,2014))
model_3 %>% predict(new_data) 
model_3


```


#### Cambiando los valores NAs por 0.
1. Se comprueba que los NAs han pasado a "nulls"
2. Y que ya no hay NAs

```{r}
m7[is.na(m7)]<-0

m7_num<-select_if(m7,is.numeric)
stat_m7<-stat.desc(m7_num)
stat_m7<-round(stat_m7,1)


stat_m7[,(stat_m7["nbr.null",]>0)] 
stat_m7[,(stat_m7["nbr.na",]>0)] 

```

#### Se importan dos indicadores de __"Woman an health"__
1. ANAEMIA_RW<-Prevalence of anaemia in women of reproductive age (%)
2. ANAEMIA_PW<- Prevalence of anaemia in pregnant women (%), 
3. Las variables contienen el valor y el intervalo de confianza, es de tipo carácter, se extrae el valor y se convierte a numérico.
4. Se tienen que pivotar las tablas de wide a longer

```{r}
ANAEMIA_RW<-read.csv("ANAEMIA_RW.csv", header=TRUE,sep = ",",stringsAsFactors = FALSE, skip=1)
ANAEMIA_RW<-ANAEMIA_RW[,c(1:8)]
colnames(ANAEMIA_RW)<-c("Who_Region","2016","2015","2014","2013","2012","2011","2010")

ANAEMIA_RW<- ANAEMIA_RW %>%
  pivot_longer(cols=`2016`:`2010`,
               names_to="year",
               values_to = "ANAEMIA_RW",
               names_ptypes = list(year=integer()))

ANAEMIA_RW$ANAEMIA_RW<-substr(ANAEMIA_RW$ANAEMIA_RW,1,4)
ANAEMIA_RW$ANAEMIA_RW<-as.numeric(ANAEMIA_RW$ANAEMIA_RW)
glimpse(ANAEMIA_RW)
unique(ANAEMIA_RW$Who_Region)
unique(ANAEMIA_RW$year)

#### ANAEMIA_PW
ANAEMIA_PW<-read.csv("ANAEMIA_PW.csv", header=TRUE,sep = ",",stringsAsFactors = FALSE, skip=1)
ANAEMIA_PW<-ANAEMIA_PW[,c(1:8)]
colnames(ANAEMIA_PW)<-c("Who_Region","2016","2015","2014","2013","2012","2011","2010")

ANAEMIA_PW<- ANAEMIA_PW %>%
  pivot_longer(cols=`2016`:`2010`,
               names_to="year",
               values_to = "ANAEMIA_PW",
               names_ptypes = list(year=integer()))

ANAEMIA_PW$ANAEMIA_PW<-substr(ANAEMIA_PW$ANAEMIA_PW,1,4)
ANAEMIA_PW$ANAEMIA_PW<-as.numeric(ANAEMIA_PW$ANAEMIA_PW)
glimpse(ANAEMIA_PW)
unique(ANAEMIA_PW$Who_Region)
unique(ANAEMIA_PW$year)
```

#### Se importa indicador __"Maternal_mortality"__
1. La variable contiene el valor y el intervalo de confianza, es de tipo carácter, se extrae el valor y se convierte a numérico.

```{r}
Maternal_Mort_Rate<-read.csv("Maternal_mortality.csv",header=TRUE,stringsAsFactors = FALSE)
Maternal_Mort_Rate<-Maternal_Mort_Rate[,c(1:3)]
colnames(Maternal_Mort_Rate)<-c("Who_Region", "year", "Maternal_Mort_Rate" )

Maternal_Mort_Rate$Maternal_Mort_Rate<-substr(Maternal_Mort_Rate$Maternal_Mort_Rate,1,3)
Maternal_Mort_Rate$Maternal_Mort_Rate<-as.numeric(Maternal_Mort_Rate$Maternal_Mort_Rate)
glimpse(Maternal_Mort_Rate)
unique(Maternal_Mort_Rate$Who_Region)
unique(Maternal_Mort_Rate$year)
```

#### Se importa "Life expectancy at birth" para ambos sexos.

```{r}
Life_expectancy_All<-read.csv("Life_expectancy_All.csv",header=TRUE,stringsAsFactors = FALSE,skip=1)
Life_expectancy_birth<-Life_expectancy_All[,c(1:3)]
colnames(Life_expectancy_birth)<-c("Who_Region", "year", "Life_expectancy_at_birth" )

glimpse(Life_expectancy_birth)
unique(Life_expectancy_birth$year)
unique(Life_expectancy_birth$Who_Region)
```


#### Se añaden al dataset los siguientes indicadores:
- ANAEMIA_RW
- ANAEMIA_PW
- Maternal_Mort_Rate
- Life_expectancy_birth

```{r}

dataset<-Reduce(function(...) merge (..., all.x=TRUE), list(m7,ANAEMIA_RW,ANAEMIA_PW,Maternal_Mort_Rate,Life_expectancy_birth))
glimpse(dataset)
unique(dataset$Who_Region)
unique(dataset$year)
```

#### Analizando valores NULOS y NAS del nuevo dataset(ya definitivo, porque no se van a incluir más variables)
1. Se identifican de la variable "Life_Expectancy_at_birth" 30 valores NAs
2. Y de las variables "ANAEMIA_RW" and "ANAEMIA_PW" 6 valores NAs para cada variable

```{r}
dataset_num<-select_if(dataset,is.numeric)
stat_dataset<-stat.desc(dataset_num)
stat_dataset<-round(stat_dataset,1)

stat_dataset[,(stat_dataset["nbr.null",]>0)] 
stat_dataset[,(stat_dataset["nbr.na",]>0)] 
```


#### Gráfico del indicador __"Life_Expectancy_at_birth"__ para ver su evolución

```{r}
dataset_Life<-dataset %>% select("Who_Region", year, Life_expectancy_at_birth)
ggplot(data=dataset_Life, aes(x=year, y=Life_expectancy_at_birth))+
  geom_point(aes(col=Who_Region))
```


#### Se decide hacer las estimaciones por **Regresión Lineal**
1. Todas los modelos tienen un R2 superior a 0.98
2. Se obtiene las predicciones con *predict*

```{r}
Life_Africa<-dataset_Life%>% filter(Who_Region=="Africa")
Life_Americas<-dataset_Life%>% filter(Who_Region=="Americas")
Life_Eastern_Mediterranean<-dataset_Life%>% filter(Who_Region=="Eastern Mediterranean")
Life_Europe<-dataset_Life%>% filter(Who_Region=="Europe")
Life_South_East_Asia<-dataset_Life%>% filter(Who_Region=="South-East Asia")
Life_Western_Pacific<-dataset_Life%>% filter(Who_Region=="Western Pacific")

model_Africa<-lm(Life_expectancy_at_birth~year,data=Life_Africa)
model_Americas<-lm(Life_expectancy_at_birth~year,data=Life_Americas)
model_Eastern_Mediterranean<-lm(Life_expectancy_at_birth~year,data=Life_Eastern_Mediterranean)
model_Europe<-lm(Life_expectancy_at_birth~year,data=Life_Europe)
model_South_East_Asia<-lm(Life_expectancy_at_birth~year,data=Life_South_East_Asia)
model_Western_Pacific<-lm(Life_expectancy_at_birth~year,data=Life_Western_Pacific)

summary(model_Africa)
summary(model_Americas)
summary(model_Eastern_Mediterranean)
summary(model_Europe)
summary(model_South_East_Asia)
summary(model_Western_Pacific)

new_data<-data.frame(year=c(2011,2012,2013,2014,2017))
pred_Africa<-model_Africa %>% predict(new_data)
pred_Americas<-model_Americas %>% predict(new_data)
pred_Eastern_Mediterranean<-model_Eastern_Mediterranean %>% predict(new_data)
pred_Europe<-model_Europe %>% predict(new_data)
pred_South_East_Asia<-model_South_East_Asia %>% predict(new_data)
pred_Western_Pacific<-model_Western_Pacific %>% predict(new_data)

pred_Africa<-data.frame(Who_Region=rep("Africa",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_Africa)
pred_Americas<-data.frame(Who_Region=rep("Americas",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_Americas)
pred_Eastern_Mediterranean<-data.frame(Who_Region=rep("Eastern Mediterranean",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_Eastern_Mediterranean)
pred_Europe<-data.frame(Who_Region=rep("Europe",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_Europe)
pred_South_East_Asia<-data.frame(Who_Region=rep("South-East Asia",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_South_East_Asia)
pred_Western_Pacific<-data.frame(Who_Region=rep("Western Pacific",5),year=c(2011,2012,2013,2014,2017),Life_expectancy_at_birth=pred_Western_Pacific)

pred_Life_all<-data.frame(rbind(pred_Africa,pred_Americas,pred_Eastern_Mediterranean,pred_Europe,pred_South_East_Asia,pred_Western_Pacific))

pred_Life_all$Who_Region<-as.character(pred_Life_all$Who_Region)
pred_Life_all$Life_expectancy_at_birth<-round(pred_Life_all$Life_expectancy_at_birth,1) 
pred_Life_all$year<-as.integer(pred_Life_all$year) 
Life_expectancy_birth<-rbind(Life_expectancy_birth,pred_Life_all)
glimpse(Life_expectancy_birth)
```

#### Analizando NAs para las variables __ANAEMIA_PW__ y __ANAEMIA_RW__
1. Observando los gráficos se decide estimar 2017 por "regresión lineal" desde el 2013, porque el evolutivo en algunas regiones (en años anteriores) no se comporta de forma lineal.

```{r}
dataset_Anaemia<-dataset %>% select(Who_Region,year,ANAEMIA_PW,ANAEMIA_RW)

ggplot(dataset_Anaemia,aes(x=year,y=ANAEMIA_PW))+
  geom_point(aes(col=Who_Region))+
  ggtitle("Evolution ANAEMIA_PW_Rate")+
  theme(plot.title = element_text(hjust = 0.5))

ggplot(dataset_Anaemia,aes(x=year,y=ANAEMIA_RW))+
  geom_point(aes(col=Who_Region))+
  ggtitle("Evolution ANAEMIA_RW_Rate")+
  theme(plot.title = element_text(hjust = 0.5))


```

#### Estimación por "lm" para el indicador "ANAEMIA_PW"
1. Todas los modelos obtienen un R2 superior a 0.83.
2. Se calculan las predicciones con *predict*
```{r}
dataset_Anaemia<-dataset %>% select(Who_Region,year,ANAEMIA_PW,ANAEMIA_RW) %>% filter (year >= "2013")

Anaemia_Africa<-dataset_Anaemia%>% filter(Who_Region=="Africa")
Anaemia_Americas<-dataset_Anaemia%>% filter(Who_Region=="Americas")
Anaemia_Eastern_Mediterranean<-dataset_Anaemia%>% filter(Who_Region=="Eastern Mediterranean")
Anaemia_Europe<-dataset_Anaemia%>% filter(Who_Region=="Europe")
Anaemia_South_East_Asia<-dataset_Anaemia%>% filter(Who_Region=="South-East Asia")
Anaemia_Western_Pacific<-dataset_Anaemia%>% filter(Who_Region=="Western Pacific")

model_Africa<-lm(ANAEMIA_PW~year,data=Anaemia_Africa)
model_Americas<-lm(ANAEMIA_PW~year,data=Anaemia_Americas)
model_Eastern_Mediterranean<-lm(ANAEMIA_PW~year,data=Anaemia_Eastern_Mediterranean)
model_Europe<-lm(ANAEMIA_PW~year,data=Anaemia_Europe)
model_South_East_Asia<-lm(ANAEMIA_PW~year,data=Anaemia_South_East_Asia)
model_Western_Pacific<-lm(ANAEMIA_PW~year,data=Anaemia_Western_Pacific)

summary(model_Africa)
summary(model_Americas)
summary(model_Eastern_Mediterranean)
summary(model_Europe)
summary(model_South_East_Asia)
summary(model_Western_Pacific)

new_data<-data.frame(year=c(2017))
pred_Africa<-model_Africa %>% predict(new_data)
pred_Americas<-model_Americas %>% predict(new_data)
pred_Eastern_Mediterranean<-model_Eastern_Mediterranean %>% predict(new_data)
pred_Europe<-model_Europe %>% predict(new_data)
pred_South_East_Asia<-model_South_East_Asia %>% predict(new_data)
pred_Western_Pacific<-model_Western_Pacific %>% predict(new_data)


pred_Africa<-data.frame(Who_Region=c("Africa"),year=c(2017),ANAEMIA_PW=pred_Africa)
pred_Americas<-data.frame(Who_Region=c("Americas"),year=c(2017),ANAEMIA_PW=pred_Americas)
pred_Eastern_Mediterranean<-data.frame(Who_Region=c("Eastern Mediterranean"),year=c(2017),ANAEMIA_PW=pred_Eastern_Mediterranean)
pred_Europe<-data.frame(Who_Region=c("Europe"),year=c(2017),ANAEMIA_PW=pred_Europe)
pred_South_East_Asia<-data.frame(Who_Region=c("South-East Asia"),year=c(2017),ANAEMIA_PW=pred_South_East_Asia)
pred_Western_Pacific<-data.frame(Who_Region=c("Western Pacific"),year=c(2017),ANAEMIA_PW=pred_Western_Pacific)

pred_Anaemia_PW<-data.frame(rbind(pred_Africa,pred_Americas,pred_Eastern_Mediterranean,pred_Europe,pred_South_East_Asia,pred_Western_Pacific))

pred_Anaemia_PW$Who_Region<-as.character(pred_Anaemia_PW$Who_Region)
pred_Anaemia_PW$ANAEMIA_PW<-round(pred_Anaemia_PW$ANAEMIA_PW,1) 
pred_Anaemia_PW$year<-as.integer(pred_Anaemia_PW$year) 
ANAEMIA_PW<-rbind(ANAEMIA_PW,pred_Anaemia_PW)
glimpse(ANAEMIA_PW)
```


#### Estimación por "lm" para el indicador "ANAEMIA_RW"
1. Todas las Regiones superan un R2 de 0.92, excepto "Africa" que obtiene un R2 muy bajo (0.16), pero se observa que los valores no tienen mucha variablidad, por tanto, se utiliza ésta.

```{r}
model_Africa<-lm(ANAEMIA_RW~year,data=Anaemia_Africa)
model_Americas<-lm(ANAEMIA_RW~year,data=Anaemia_Americas)
model_Eastern_Mediterranean<-lm(ANAEMIA_RW~year,data=Anaemia_Eastern_Mediterranean)
model_Europe<-lm(ANAEMIA_RW~year,data=Anaemia_Europe)
model_South_East_Asia<-lm(ANAEMIA_RW~year,data=Anaemia_South_East_Asia)
model_Western_Pacific<-lm(ANAEMIA_RW~year,data=Anaemia_Western_Pacific)

summary(model_Africa)
summary(model_Americas)
summary(model_Eastern_Mediterranean)
summary(model_Europe)
summary(model_South_East_Asia)
summary(model_Western_Pacific)

new_data<-data.frame(year=c(2017))
pred_Africa<-model_Africa %>% predict(new_data)
pred_Americas<-model_Americas %>% predict(new_data)
pred_Eastern_Mediterranean<-model_Eastern_Mediterranean %>% predict(new_data)
pred_Europe<-model_Europe %>% predict(new_data)
pred_South_East_Asia<-model_South_East_Asia %>% predict(new_data)
pred_Western_Pacific<-model_Western_Pacific %>% predict(new_data)


pred_Africa<-data.frame(Who_Region=c("Africa"),year=c(2017),ANAEMIA_RW=pred_Africa)
pred_Americas<-data.frame(Who_Region=c("Americas"),year=c(2017),ANAEMIA_RW=pred_Americas)
pred_Eastern_Mediterranean<-data.frame(Who_Region=c("Eastern Mediterranean"),year=c(2017),ANAEMIA_RW=pred_Eastern_Mediterranean)
pred_Europe<-data.frame(Who_Region=c("Europe"),year=c(2017),ANAEMIA_RW=pred_Europe)
pred_South_East_Asia<-data.frame(Who_Region=c("South-East Asia"),year=c(2017),ANAEMIA_RW=pred_South_East_Asia)
pred_Western_Pacific<-data.frame(Who_Region=c("Western Pacific"),year=c(2017),ANAEMIA_RW=pred_Western_Pacific)

pred_Anaemia_RW<-data.frame(rbind(pred_Africa,pred_Americas,pred_Eastern_Mediterranean,pred_Europe,pred_South_East_Asia,pred_Western_Pacific))

pred_Anaemia_RW$Who_Region<-as.character(pred_Anaemia_RW$Who_Region)
pred_Anaemia_RW$ANAEMIA_RW<-round(pred_Anaemia_RW$ANAEMIA_RW,1) 
pred_Anaemia_RW$year<-as.integer(pred_Anaemia_RW$year) 
ANAEMIA_RW<-rbind(ANAEMIA_RW,pred_Anaemia_RW)
glimpse(ANAEMIA_RW)
```

#### Actualizando los valores estimados en el "dataset"

```{r}
dataset<-dataset %>% select(-Life_expectancy_at_birth,-ANAEMIA_RW,-ANAEMIA_PW) ## por error reiterativo en el merge siguiente, se decide incluir esta línea de comandos para solucionarlo.
dataset<-Reduce(function(...) merge (..., all.x=TRUE), list(dataset,ANAEMIA_RW,ANAEMIA_PW,Life_expectancy_birth))
glimpse(dataset)
unique(dataset$Who_Region)
unique(dataset$year)
```

#### Verificando estadísticas del dataset y los valores Nulls & NAs.
1. Ya no tenemos más valores NAs que estimar, el indicador sale a 0.
```{r}
dataset_num<-select_if(dataset,is.numeric)
stat_dataset<-stat.desc(dataset_num)
stat_dataset<-round(stat_dataset,1)
stat_dataset

stat_dataset[,(stat_dataset["nbr.null",]>0)] 
stat_dataset[,(stat_dataset["nbr.na",]>0)] 
```

#### SELECCIÓN DE MODELOS: __REGRESION PENALIZADA "CRESTA"__
1. Se va a aplicar para validar el modelo **"Cross Validation K-fold(5)"**
2. Se utilizará la función *train* del paquete **caret** con la selección **alpha=0** para el modelo **Cresta**
3. Se estandarizan los datos con "scale=TRUE" 
4. La regresión de cresta reduce los coeficientes de regresión, de modo que las variables, con una contribución menor al resultado, tienen sus coeficientes cercanos a cero. La penalización se ajusta utilizando una constante lambda.
5. Una desventaja es que incluirá todos los coeficientes en el modelo final.

```{r}
set.seed(123)
training_samples<-dataset$Rate_Mort_Child %>%
  createDataPartition(p=0.8,list=FALSE)
train_data<-dataset[training_samples,]
test_data<-dataset[-training_samples,]

lambda<-seq(-3,3,length=100)
set.seed(123)
model_ridge<- train(
  Rate_Mort_Child~.,data=train_data,method="glmnet",
  trControl=trainControl("cv",number=5),
  scale=TRUE,
  tuneGrid=expand.grid(alpha=0,lambda=lambda)
)

data.frame("best_lambda", value=model_ridge$bestTune$lambda)
coef(model_ridge$finalModel,model_ridge$bestTune$lambda)
```

#### Métricas resultado "Cross-Validation k-fold" para "Cresta"
1. Se observa que el R2 es bueno (0.98), pero el RMSE y el MAE, son muy altos, obteniendo una Tasa de Error en Train del 23%.
```{r}
Metricas_train_ridge<-data.frame("metrics_train"="metrics_train_ridge",Mean_RMSE=mean(model_ridge$resample$RMSE),
Mean_MAE=mean(model_ridge$resample$MAE),
Mean_RSquared=mean(model_ridge$resample$Rsquared),
Tasa_Error_Train=mean(model_ridge$resample$RMSE)/mean(train_data$Rate_Mort_Child))


Metricas_train_ridge
```

#### Métricas de las predicciones para test en Regression "Cresta"
1. Tasa de Error para test, muy elevada casi 26%. Con RMSE y MAE, también muy altos. Y R2 bueno.
2. Comparando train y test, observamos que no hay overfitting.
```{r}

predictions_ridge<-model_ridge %>% predict(test_data)
Metricas_ridge_test<-data.frame("metrics_test"="metrics_test_ridge",
  RMSE=RMSE(predictions_ridge,test_data$Rate_Mort_Child),
  MAE=MAE(predictions_ridge,test_data$Rate_Mort_Child),
  Rsquare=caret::R2(predictions_ridge,test_data$Rate_Mort_Child),
  Tasa_Error_Test=RMSE(predictions_ridge,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child)
)
Metricas_ridge_test
```


#### SELECCIÓN DE MODELOS: __REGRESION PENALIZADA "LASSO"__
1. Se va a aplicar para validar el modelo **"Cross Validation K-fold(5)"**
2. Se utilizará la función *train* del paquete **caret** con la selección **alpha=1** para el modelo **Lasso**
3. Se estandarizan los datos con "scale=TRUE" 
4. La regresión de Lasso tiene el efecto de forzar que algunas estimaciones de coeficientes de contribución menor, sean exactamente iguales a 0.
5. La ventaja es que producirá modelos más simples e interpretables que la regresión de cresta.
6. El modelo incluiría estas variables: **Mort_Congenital_rate + Mort_Diarrhoeal_rate + Mort_Meningitis_rate + Mort_Other_rate + Mort_Respiratory_rate + Life_expectancy_at_birth**

```{r}
lambda<-seq(-3,3,length=100)
set.seed(123)
model_lasso<- train(
  Rate_Mort_Child~.,data=train_data,method="glmnet",
  trControl=trainControl("cv",number=5),
  scale=TRUE,
  tuneGrid=expand.grid(alpha=1,lambda=lambda)
)

data.frame("best_lambda", value=model_lasso$bestTune$lambda)

coef(model_lasso$finalModel,model_lasso$bestTune$lambda)

```

#### Métricas resultado "Cross-Validation k-fold" para "Lasso"
1. Valores mucho mejores que para la regresión con Cresta, la tasa de Error no supera el 2.5%, con un R2 de 99.95%, y unos valores de RMSE y MAE no superiores a 1.
```{r}
Metricas_train_lasso<-data.frame("metrics_train"="metrics_train_lasso",Mean_RMSE=mean(model_lasso$resample$RMSE),Mean_MAE=mean(model_lasso$resample$MAE),
Mean_RSquared=mean(model_lasso$resample$Rsquared),
Tasa_Error_Train=mean(model_lasso$resample$RMSE)/mean(train_data$Rate_Mort_Child)) 

Metricas_train_lasso
```



#### Métricas de las predicciones para test "Lasso"
1. Valores muy similares a los de train, lo que quieres decir que no tenemos overfitting.
```{r}
predictions_lasso<-model_lasso %>% predict(test_data)
Metricas_lasso_test<-data.frame("metrics_test"="metrics_test_lasso",
  RMSE=RMSE(predictions_lasso,test_data$Rate_Mort_Child),
  MAE=MAE(predictions_lasso,test_data$Rate_Mort_Child),
  RSquared=caret::R2(predictions_lasso,test_data$Rate_Mort_Child),
  Tasa_Error_Test=RMSE(predictions_lasso,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child)
)
Metricas_lasso_test
```


#### SELECCIÓN DE MODELOS: __REGRESION PENALIZADA "NET ELASTIC"__
1. Se va a aplicar para validar el modelo **"Cross Validation K-fold(5)"**
2. Se utilizará la función *train* del paquete **caret** con **tuneLength=10** para el modelo **Net_Elastic**
3. Se estandarizan los datos con "scale=TRUE" 
4. Produce un modelo regresión penalizado tanto por la L1-Norma y L2-Norma, para reducir los coeficientes (como en la regresión de Cresta) y establecer algunos coeficientes a 0 (como en la regresión de Lasso)
5. Con el paquete caret y la opción *tuneLength=10* se seleccionarán automáticamente los mejores parámetros de ajuste alpha y y lambda (combinaciones de 10 valores diferentes de alpha y lambda). Los mejores son los que minimizan el error de la validación cruzada.
6. El warning **There were missing values in resampled performance measures** que sale es para la combinación de algunos parámetros de alpha y lambda(se muestra el data.frame con los NaN).
7. Alpha=0.4 y lambda=1.28 son los parámetros que minimizan el error de validación cruzada.
8. El modelo final incluiría no sólo variables de **"Mort_Rate_Cause"**, también del grupo **"International_Health_Regulations"**, del grupo **"Inmunization"**, **"Child_Malnutrition"** y ** "Life_Expectancy"**

```{r}
set.seed(123)
model_elastic<- train(
  Rate_Mort_Child~.,data=train_data,method="glmnet",
  trControl=trainControl("cv",number=5),
  scale=TRUE,
  tuneLength=10
)
data.frame("best_parameter", model_elastic$bestTune)

coef(model_elastic$finalModel,model_elastic$bestTune$lambda)

elas_results<-model_elastic$results
elas_results %>% filter(elas_results$Rsquared=="NaN")
```

#### Métricas resultado "Cross-Validation k-fold" para "Net Elastic"
1. Tasa de Error medio bastante buena (2.9%), algo superior a Lasso, cn un R2 algo inferior.
```{r}
Metricas_train_elastic<-data.frame("metrics_train"="metrics_train_elastic",Mean_RMSE=mean(model_elastic$resample$RMSE),Mean_MAE=mean(model_elastic$resample$MAE),
Mean_RSquared=mean(model_elastic$resample$Rsquared),
Tasa_Error_Train=mean(model_elastic$resample$RMSE)/mean(train_data$Rate_Mort_Child)) 

Metricas_train_elastic
```



#### Métricas de las predicciones para test.
1. Valores muy similares a los de train, no tenemos overfitting.
```{r}
predictions_elastic<-model_elastic %>% predict(test_data)
Metricas_elastic_test<-data.frame("metrics_test"="metrics_test_elastic",
  RMSE=RMSE(predictions_elastic,test_data$Rate_Mort_Child),
  MAE=MAE(predictions_elastic,test_data$Rate_Mort_Child),
  Rsquare=caret::R2(predictions_elastic,test_data$Rate_Mort_Child),
  Tasa_Error_Test=RMSE(predictions_elastic,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child)
)
Metricas_elastic_test
```



#### COMPARATIVA RENDIMIENTO DEL MODELO "MEDIA DE LAS MÉTRICAS" en "Cross validation k-fold"
1. La regresion penalizada de Lasso es la que mejores métricas tiene, muy seguida de "Net-Elastic" 

```{r}
metricas_train_wide<-data.frame(rbind(Metricas_train_ridge,Metricas_train_lasso,Metricas_train_elastic))

metricas_train_wide[,-1]<-round(metricas_train_wide[,-1],4)

metricas_train_wide

metricas_train_longer <- metricas_train_wide %>%
  pivot_longer(cols="Mean_RMSE":"Tasa_Error_Train",
               names_to="names",
               values_to = "value")

ggplot(data=metricas_train_longer,aes(x=names,y=value, fill=metrics_train))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas en Cross Validation*
          para modelos de *Regresión PENALIZADA*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette="Blues")

```


#### COMPARATIVA MÉTRICAS "MODEL PREDICTION PERFORMANCE" (TEST)

```{r}
metricas_test_wide<-data.frame(rbind(Metricas_ridge_test,Metricas_lasso_test,Metricas_elastic_test))

metricas_test_wide[,-1]<-round(metricas_test_wide[,-1],4)

metricas_test_wide

metricas_test_longer <- metricas_test_wide %>%
  pivot_longer(cols="RMSE":"Tasa_Error_Test",
               names_to="names",
               values_to = "value")

ggplot(data=metricas_test_longer,aes(x=names,y=value, fill=metrics_test))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas de Rendimiento* en TEST 
para modelos de *Regresión PENALIZADA*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
 scale_fill_brewer( palette="Reds") 
```



#### Análisis de los supuestos de Regresión lineal con __"lm"__ para las variables identificadas por Lasso.
Comentar que el modelo lineal tiene un R2=0.9998 muy bueno, y que tanto el intercept cómo los coeficientes de las variables predictoras varían respecto al "CV k-fold", cómo es lógico. 

1. **Linealidad de los datos**-> Gráfica Residual vs Fitted-> 
Se utiliza para verificar los supuestos de relación lineal.Una línea horizontal sin patrones distintos, es una indicación de una relación lineal. En nuestro caso, prácticamente se mueve entorno a 0, es decir, asumimos linealidad entre predictores y variable resultado.
2. **Normalidad de los residuos**-> Gráfica Normal Q-Q-> 
Se utiliza para examinar si los residuos se distribuyen normalmente. Es bueno si los puntos residuales siguen la linea recta discontinua.En nuestro caso la mayoría siguen la línea, excepto los valores atípicos y algunos puntuales.
3. **Homogeneidad de la varianza residual(homocedasticidad)**-> Gráfica Scale-Location-> 
La línea horizontal con puntos igualmente extendidos es una buena indicación de              homocedasticidad.En nuestros caso el comportamiento es de poca variación (entorno 0.5),       por tanto, asumimos "homocedasticidad"
4. **Independencia de los términos de error de residuos**. -> Gráfica Scale-Location  

```{r}
lm_model_lasso<-lm(Rate_Mort_Child~Mort_Congenital_rate + Mort_Diarrhoeal_rate+
     Mort_Meningitis_rate+Mort_Other_rate+
     Mort_Respiratory_rate+Life_expectancy_at_birth, data=train_data)
summary(lm_model_lasso)  

par(mar=c(2,2,2,2))
plot(lm_model_lasso,1)
plot(lm_model_lasso,2)
plot(lm_model_lasso,3)

```


#### Análisis de __Valores Influyentes__:
**Gráfico Residuals vs Leverage**-> Se utiliza para identificar casos influyentes. 

1. **Valores atípicos**-> Las observaciones cuyos residuos estandarizados son mayores que 3 en  valor absoluto son posibles valores atípicos.En nuestro caso resaltan 3 puntos más extremos(#1,#9,#34),con resdiduos estandarizados por debajo de 3, excepto el#9 (4.06)
2. **Puntos de apalacamiento**-> Se puede detectar examinando la estadistica de ".hat". Un valor superior a 2(p+1)/n indicaría una observación con alto apalancamiento. En nuestro caso 2(42+1)/40=2.15. Ninguno supera el 0.45
3. **Valores influyentes**-> Es un valor cuya inclusión o exclusión altera los resultados del análisis de regresión. No todos los valores atípicos influyen en el análisis de regresión. La "distancia de Cook" determina la influencia de un valor. Esta métrica define la influencia como una combinación de apalancamiento y tamaño residual. En nuestro caso ningun punto es influyente, porque están dentro de los límites marcados por la distancia de Cook 4/(n-p-1) = 4/(40-42-1)=-1,33
```{r}

#### Tabla con las métricas del diagnóstico
model_diag_metrics<-augment(lm_model_lasso)
model_diag_metrics

#### Identificando los tres valores extremos
top_3_cook<-model_diag_metrics %>%
  top_n(3,wt=.cooksd)
top_3_cook

par(mar=c(2,2,2,2))
plot(lm_model_lasso,4)
plot(lm_model_lasso,5)

```



#### Se decide excluir el registro #9 (valor atípico) para ver el comportamiento del "lineal model":
1. Mejora el R2, sin mucha variación en los coeficientes,los residuos se ajustan bien en la gráfico Normal Q-Q, y el resto de gráficas son similares.
```{r}
#train_data[which(rownames(train_data)==1),]
#Excluyendo los valores extremos del dataset train_data
train_data_exc<-train_data %>% filter(Rate_Mort_Child!=19.4)
glimpse(train_data_exc)

#### Aplicando "lm"
lm_model_lasso_exc<-lm(Rate_Mort_Child~Mort_Congenital_rate + Mort_Diarrhoeal_rate+
     Mort_Meningitis_rate+Mort_Other_rate+
     Mort_Respiratory_rate+Life_expectancy_at_birth, data=train_data_exc)
summary(lm_model_lasso_exc)  

par(mar=c(2,2,2,2))
plot(lm_model_lasso_exc,1)
plot(lm_model_lasso_exc,2)
plot(lm_model_lasso_exc,3)
plot(lm_model_lasso_exc,4)
plot(lm_model_lasso_exc,5)
```

#### SELECCIÓN DE MODELOS: __STEPWISE "leapBackward"__
1. Comienza con todos los predictores en el modelo, y elimina de forma iterativa los predictores menos contributivos, se detiene cuando tiene un modelo dónde todos los predictores son estadísticamente significativos. 
2. Se debe especificar el número máximo de predictores que se incorporaran al modelo (nvmax=10).
3. Se utilizará la validación cruzada 5 veces para estimar el error de predicción promedio (RMSE)
4. Se estandariza las variables con *scale=TRUE*

```{r}
set.seed(234)
train_control<-trainControl(method = "cv",number=5)
step_model_Back<-train(Rate_Mort_Child~.,data=train_data,
                       method="leapBackward",
                       tuneGrid=data.frame(nvmax=1:10),
                       trControl=train_control,
                       scale=TRUE)

step_model_Back
step_model_Back$bestTune
coef_step_Back<-coef(step_model_Back$finalModel,9)
data.frame(round(coef_step_Back,3))
metrics_train<-step_model_Back$results[9,2:4]
Metricas_train_leapBackward<-data.frame("metrics_train"="metrics_train_leapBackward",
           Mean_RMSE=metrics_train$RMSE,
           Mean_MAE=metrics_train$MAE,
           Mean_RSquared=metrics_train$Rsquared, 
           Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))

Metricas_train_leapBackward
predictions_leap_Back<-step_model_Back %>% predict(test_data)
Metricas_leapBack_test<-data.frame("metrics_test"="metrics_test_leapBack",
                               RMSE=RMSE(predictions_leap_Back,test_data$Rate_Mort_Child),
                               MAE=MAE(predictions_leap_Back,test_data$Rate_Mort_Child),
                               RSquared=caret::R2(predictions_leap_Back,test_data$Rate_Mort_Child),
                               Tasa_Error_Test=RMSE(predictions_leap_Back,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))

Metricas_leapBack_test

```


#### SELECCIÓN DE MODELOS: __STEPWISE "leapForward"__
1. Comienza sin predictores en el modelo, agregra iterativamente los predictores más contributivos y se detiene cuando la mejora ya no es estadisticamente significativa.
2. Se debe especificar el número máximo de predictores que se incorporaran al modelo (nvmax=10).
3. Se utilizará la validación cruzada 5 veces para estimar el error de predicción promedio (RMSE)
4. Se estandariza las variables con *scale=TRUE*

```{r}
set.seed(234)
train_control<-trainControl(method = "cv",number=5)
step_model_Forward<-train(Rate_Mort_Child~.,data=train_data,
                       method="leapForward",
                       tuneGrid=data.frame(nvmax=1:10),
                       trControl=train_control,
                       scale=TRUE)

step_model_Forward
step_model_Forward$bestTune
coef_step_Forward<-coef(step_model_Forward$finalModel,8)
data.frame(round(coef_step_Forward,3))
metrics_train<-step_model_Forward$results[9,2:4]
Metricas_train_leapForward<-data.frame("metrics_train"="metrics_train_leapForward",
                                       Mean_RMSE=metrics_train$RMSE,
                                       Mean_MAE=metrics_train$MAE,
                                       Mean_RSquared=metrics_train$Rsquared, 
                                       Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))

Metricas_train_leapForward
predictions_leap_Forward<-step_model_Forward %>% predict(test_data)
Metricas_leapForward_test<-data.frame("metrics_test"="metrics_test_leapForward",
                                   RMSE=RMSE(predictions_leap_Forward,test_data$Rate_Mort_Child),
                                   MAE=MAE(predictions_leap_Forward,test_data$Rate_Mort_Child),
                                   RSquared=caret::R2(predictions_leap_Forward,test_data$Rate_Mort_Child),
                                   Tasa_Error_Test=RMSE(predictions_leap_Forward,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))

Metricas_leapForward_test

```



#### SELECCIÓN DE MODELOS: __ STEPWISE "leapSeq""__

1. Es una combinación entre "leapBackward" y "leapForward".Comienza sin predictores y luego agrega secuencialmente los predictores más contribuyentes. Después de agregar cada nueva variable, elimina cualquier variable que ya no proporciona una mejora en el ajuste del modelo.
2. Se debe especificar el número máximo de predictores que se incorporaran al modelo (nvmax=10).
3. Se utilizará la validación cruzada 5 veces para estimar el error de predicción promedio (RMSE)
4. Se estandariza las variables con *scale=TRUE*

```{r}
set.seed(345)
train_control<-trainControl(method = "cv",number=5)
step_model_leapSeq<-train(Rate_Mort_Child~.,data=train_data,
                          method="leapSeq",
                          tuneGrid=data.frame(nvmax=1:10),
                          trControl=train_control,
                          scale=TRUE)

step_model_leapSeq
step_model_leapSeq$bestTune
coef_step_leapSeq<-coef(step_model_leapSeq$finalModel,7)
data.frame(round(coef_step_leapSeq,3))
metrics_train<-step_model_leapSeq$results[9,2:4]
Metricas_train_leapSeq<-data.frame("metrics_train"="metrics_train_leapSeq",
                                       Mean_RMSE=metrics_train$RMSE,
                                       Mean_MAE=metrics_train$MAE,
                                       Mean_RSquared=metrics_train$Rsquared,                                Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))

Metricas_train_leapSeq
predictions_leap_Seq<-step_model_leapSeq %>% predict(test_data)
Metricas_leapSeq_test<-data.frame("metrics_test"="metrics_test_leapSeq",
                                      RMSE=RMSE(predictions_leap_Seq,test_data$Rate_Mort_Child),
                                      MAE=MAE(predictions_leap_Seq,test_data$Rate_Mort_Child),                                RSquared=caret::R2(predictions_leap_Seq,test_data$Rate_Mort_Child),                            Tasa_Error_Test=RMSE(predictions_leap_Seq,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))

Metricas_leapSeq_test
```


#### Comparativa **Métricas** en CROSS VALIDATION, para modelos *STEPWISE*
```{r}
metricas_train_wide<-data.frame(rbind(Metricas_train_leapBackward,Metricas_train_leapForward,Metricas_train_leapSeq))

metricas_train_wide[,-1]<-round(metricas_train_wide[,-1],4)

metricas_train_wide

metricas_train_longer <- metricas_train_wide %>%
  pivot_longer(cols="Mean_RMSE":"Tasa_Error_Train",
               names_to="names",
               values_to = "value")

ggplot(data=metricas_train_longer,aes(x=names,y=value, fill=metrics_train))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas en Cross Validation*
 para modelos *STEPWISE*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette=11)

```


#### Comparativa **Métricas de Rendimiento** en TEST, para modelos *STEPWISE*
```{r}
metricas_test_wide<-data.frame(rbind(Metricas_leapBack_test,Metricas_leapForward_test,Metricas_leapSeq_test))

metricas_test_wide[,-1]<-round(metricas_test_wide[,-1],4)

metricas_test_wide

metricas_test_longer <- metricas_test_wide %>%
  pivot_longer(cols="RMSE":"Tasa_Error_Test",
               names_to="names",
               values_to = "value")

ggplot(data=metricas_test_longer,aes(x=names,y=value, fill=metrics_test))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas de Rendimiento* en TEST 
para modelos *STEPWISE*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette=5)


```




#### Análisis de los supuestos de Regresión lineal con __"lm"__ para las variables identificadas por el modelo **Setpwise leapForward**
Comentar que el modelo lineal tiene un excelente R2=0.9999 , y que tanto el intercept cómo los coeficientes de las variables predictoras son muy similares respecto al "CV k-fold", cómo es lógico por el propio algoritmo del modelo de ir incluyendo variables.

1. **Linealidad de los datos**-> Gráfica Residual vs Fitted-> 
Se utiliza para verificar los supuestos de relación lineal.Una línea horizontal sin patrones distintos, es una indicación de una relación lineal. En nuestro caso, prácticamente se mueve entorno a 0, es decir, asumimos linealidad entre predictores y variable resultado.
2. **Normalidad de los residuos**-> Gráfica Normal Q-Q-> 
Se utiliza para examinar si los residuos se distribuyen normalmente. Es bueno si los puntos residuales siguen la linea recta discontinua.En nuestro caso hay ciertas irregularidades en los puntos, observando escalones entonor al 0, haremos una transformación logarítmica para ver si se corrige.
3. **Homogeneidad de la varianza residual(homocedasticidad)**-> Gráfica Scale-Location-> 
La línea horizontal con puntos igualmente extendidos es una buena indicación de              homocedasticidad. En nuestro caso el comportamiento es de poca variación pero entorno al 1, asumimos "homocedasticidad"
4. **Independencia de los términos de error de residuos**. -> Gráfica Scale-Location. Idem al anterior.

**Gráfico Residuals vs Leverage**-> Se utiliza para identificar casos influyentes. 

1. **Valores atípicos**-> Las observaciones cuyos residuos estandarizados son mayores que 3 en  valor absoluto son posibles valores atípicos.En nuestro caso resaltan 3 puntos más extremos(#9,#32,#48),con residuos estandarizados por debajo de 3.
2. **Puntos de apalacamiento**-> Se puede detectar examinando la estadistica de ".hat". Un valor superior a 2(p+1)/n indicaría una observación con alto apalancamiento. En nuestro caso 2(42+1)/40=2.15. No supera ningún valor el 0,61.
3. **Valores influyentes**-> Es un valor cuya inclusión o exclusión altera los resultados del análisis de regresión. No todos los valores atípicos influyen en el análisis de regresión. La "distancia de Cook" determina la influencia de un valor. Esta métrica define la influencia como una combinación de apalancamiento y tamaño residual. En nuestro caso ningun punto es influyente, porque están dentro de los límites marcados por la distancia de Cook [4/(n-p-1)= 4/(40-42-1) = 1.33]
```{r}
lm_model_Forward<-lm(Rate_Mort_Child~Response+Mort_Congenital_rate+
                       Mort_Diarrhoeal_rate+Mort_Other_rate+
                       Mort_Respiratory_rate+Inm_DTP3_coverage+
                       Inm_Hib3_coverage+Inm_PCV3_coverage, data=train_data)
summary(lm_model_Forward)
model_diag_Forward<-augment(lm_model_Forward)
model_diag_Forward
top_3_cook<-model_diag_Forward %>%
  top_n(3,wt=.cooksd)
top_3_cook
par(mar=c(2,2,2,2))
plot(lm_model_Forward,1)
plot(lm_model_Forward,2)
plot(lm_model_Forward,3)
plot(lm_model_Forward,4)
plot(lm_model_Forward,5)
```


#### Transformación logarítmica de la variable objetivo para corregir la gráfica Normal Q-Q.
1. Ahora los puntos siguen más la línea recta, aunque en las colas están más dispersos.
```{r}
lm_model_Forward<-lm(log(Rate_Mort_Child)~Response+Mort_Congenital_rate+
                      Mort_Diarrhoeal_rate+Mort_Other_rate+
                      Mort_Respiratory_rate+Inm_DTP3_coverage+
                      Inm_Hib3_coverage+Inm_PCV3_coverage, data=train_data)
summary(lm_model_Forward)
model_diag_Forward<-augment(lm_model_Forward)
model_diag_Forward
top_3_cook<-model_diag_Forward %>%
  top_n(3,wt=.cooksd)
top_3_cook
par(mar=c(2,2,2,2))
plot(lm_model_Forward,1)
plot(lm_model_Forward,2)
plot(lm_model_Forward,3)
plot(lm_model_Forward,4)
plot(lm_model_Forward,5)
```


#### SELECCIÓN DE MODELOS: __**REGSUBSETS**__
1. Es un enfoque de selección de modelo que consiste en probar todas las combinaciones posibles de las variables predictoras, para luego seleccionar el mejor modelo de acuerdo a algunos estadísticos.
2. Se debe especificar la opción *nvmax* que representa el número máximo de predictores, en nuestro caso serán 10.
3. Y el modelo que obtiene las mejores métricas es el de 10 variables.
```{r}
models_reg<- regsubsets(Rate_Mort_Child~.,data=train_data,nvmax=10)
res_sum<-summary(models_reg)
data.frame(
  Adj.R2=which.max(res_sum$adjr2),
  BIC=which.min(res_sum$bic)
)
coef(models_reg,10)

#### Función para acceder a la fórmula de cualquier modelo "regsubsets"
get_model_formula<-function(id,object,outcome){
  models<-summary(object)$which[id,-1]
  predictors<-names(which(models==TRUE))
  predictors<-paste(predictors,collapse="+")
  as.formula(paste0(outcome,"~",predictors))
}
model_formula=get_model_formula(10,models_reg,"Rate_Mort_Child")
model_formula
```

#### __**REGSUBSETS**__ aplicando **CROSS VALIDATION K-FOLD**.
1. Un enfoque más riguroso es seleccionar un modelo basado en "Cross Validation", que es lo que aplicaremos ahora.
2. El modelo de 10 variables es el que mejores métricas tiene en CV. 
3. Pero presenta overfitting. El gráfico se muestra en el siguiente apartado.

```{r}

#### Función para obtener el error RMSE de validación cruzada (CV)
get_cv_error_RMSE<-function(model_formula,data){
  set.seed(1)
  train_control<-trainControl(method="cv",
                              number = 5)
  cv<-train(model_formula,data=train_data,method="lm",
                trControl=train_control)
  cv$results$RMSE
}
#### Compute cross-validation error RMSE
model_ids<-1:10
cv_errors_RMSE<-map(model_ids,get_model_formula,models_reg,"Rate_Mort_Child") %>%
  map(get_cv_error_RMSE,data=train_data) %>%
  unlist()

#### Función para obtener el error MAE de validación cruzada (CV)
get_cv_error_MAE<-function(model_formula,data){
  set.seed(1)
  train_control<-trainControl(method="cv",
                              number = 5)
  cv<-train(model_formula,data=train_data,method="lm",
            trControl=train_control)
  cv$results$MAE
}
#### Compute cross-validation error MAE
model_ids<-1:10
cv_errors_MAE<-map(model_ids,get_model_formula,models_reg,"Rate_Mort_Child") %>%
  map(get_cv_error_MAE,data=train_data) %>%
  unlist()
#### Función para obtener el R2 de validación cruzada (CV)
get_cv_error_R2<-function(model_formula,data){
  set.seed(1)
  train_control<-trainControl(method="cv",
                              number = 5)
  cv<-train(model_formula,data=train_data,method="lm",
            trControl=train_control)
  cv$results$Rsquared
} 
#### Compute cross-validation R2
model_ids<-1:10
cv_errors_R2<-map(model_ids,get_model_formula,models_reg,"Rate_Mort_Child") %>%
  map(get_cv_error_R2,data=train_data) %>%
  unlist()

data.frame(cbind(model_id=c(1:10),cv_errors_RMSE,cv_errors_MAE,cv_errors_R2))

model_best_regsubsets<-lm(Rate_Mort_Child ~ Surveillance + Mort_Congenital_rate + Mort_Diarrhoeal_rate + 
     Mort_HIVAIDS_dis_rate + Mort_Malaria_rate + Mort_Other_rate + 
     Mort_Prematurity_rate + Inm_PCV3_coverage + Maternal_Mort_Rate + 
     ANAEMIA_PW, data=train_data)


Metricas_train_best_regsubsets<-data.frame("metrics_train"="metrics_train_best_regsubsets",
                                        Mean_RMSE=cv_errors_RMSE[which.min(cv_errors_RMSE)],
                                        Mean_MAE=cv_errors_MAE[which.min(cv_errors_MAE)],
                                        Mean_RSquared=cv_errors_R2[which.max(cv_errors_R2)], 
                                        Tasa_Error_Train=cv_errors_RMSE[which.min(cv_errors_RMSE)]/mean(train_data$Rate_Mort_Child))

Metricas_train_best_regsubsets

predictions_best_regsubsets<-model_best_regsubsets %>% predict(test_data)

Metricas_best_regsubsets_test<-data.frame("metrics_test"="metrics_test_regsubsets",
                                   RMSE=RMSE(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                   MAE=MAE(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                   RSquared=caret::R2(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                   Tasa_Error_Test=RMSE(predictions_best_regsubsets,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))

Metricas_best_regsubsets_test

```


#### GRÁFICO COMPARATIVA MÉTRICAS TRAIN/TEST PARA EL MEJOR MODELO REGSUBSETS.
1. El mejor modelo de "10 variables" consi
```{r}
train<-data.frame("metrics"="metrics_train_regsubsets",
                                           RMSE=cv_errors_RMSE[which.min(cv_errors_RMSE)],
                                           MAE=cv_errors_MAE[which.min(cv_errors_MAE)],
                                           RSquared=cv_errors_R2[which.max(cv_errors_R2)], 
                                           Tasa_Error=cv_errors_RMSE[which.min(cv_errors_RMSE)]/mean(train_data$Rate_Mort_Child))
test<-data.frame("metrics"="metrics_test_regsubsets",
                                          RMSE=RMSE(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                          MAE=MAE(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                          RSquared=caret::R2(predictions_best_regsubsets,test_data$Rate_Mort_Child),
                                          Tasa_Error=RMSE(predictions_best_regsubsets,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))

metricas_reg<-data.frame(rbind(train,test))



metrics_reg_longer <- metricas_reg %>%
  pivot_longer(cols=`RMSE`:`Tasa_Error`,
               names_to="name_metrics",
               values_to = "values",
               names_ptypes = list(year=integer()))

metrics_reg_longer$values<-round(metrics_reg_longer$values,5)

ggplot(data=metrics_reg_longer,aes(x=name_metrics,y=values, fill=metrics))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=values),position=position_dodge(width=0.9), vjust=2,size=3)+
  ggtitle("Comparativa Métricas *Train/Test*
    para el mejor modelo *REGSUBSETS*")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette=15) 
```

#### Verificando las hipótesis de regresión lineal.
1.Comprobamos que cumple las hipótesis de linealidad
```{r}
model_best_regsubsets
summary(model_best_regsubsets)

model_diag_Reg<-augment(model_best_regsubsets)
model_diag_Reg
top_3_cook<-model_diag_Reg %>%
  top_n(3,wt=.cooksd)
top_3_cook

par(mar=c(2,2,2,2))
plot(model_best_regsubsets,1)
plot(model_best_regsubsets,2)
plot(model_best_regsubsets,3)
plot(model_best_regsubsets,4)
plot(model_best_regsubsets,5)

```





#### SELECCIÓN DE MODELOS: REGRESIÓN DE __**COMPONENTES PRINCIPALES**__ (PCR)
1. La regresión de componentes principales primero aplica el "Ánalisis de componentes principales" en el conjunto de datos para resumir las variables predictoras originales en pocas variables nuevas, también conocidas como componenetes principales (PC), que son una combinación lineal de los datos originales.
2. Un inconveniente de la PCR es que no tenemos garantía de que las componentes principales seleccionados estén asociados con el resultado. La selección de componentes principales para incorporar en el modelo no está supervisada por la variable resultado.
3. Se utiliza *Cross Validation* para identificar automáticamente el número óptimo de componentes principales **ncomp**
4. Con la opción *tuneLength* probaremos 9 valores diferentes del parámetro de ajuste *ncomp*.
5. La opción *scale=TRUE* para estandarizar las variables
6. Nuestro análisis prueba que al elegir 10 componentes principales (ncomp=10) se obtiene el menor error de predicción RMSE. El 97,99% de la variación contenida en los predictores son capturados por 10 componentes principales. Además captura el 99,87% de la información de la variable resultado.
7. Se muestra gráfico con el % de Importancia de las variables.Siendo las variables por encima de un 98% las siguientes:
>.- Mort_Diarrhoeal_rate
>.- Mort_Asphyxia_rate
>.- Mort_Respiratory_rate
>.- Mort_Other_rate
>.- Life_expectancy_at_birth
>.- Who_Región
>.- ANAEMIA_Children5

```{r}
set.seed(278)
model_pcr<-train(Rate_Mort_Child~., data=train_data,
                 method="pcr",
                 scale=TRUE,
                 trControl=trainControl("cv",number=5),
                 tuneLength=10)
plot(model_pcr,main="Componentes vs RMSE")

model_pcr$bestTune
summary(model_pcr)
model_pcr$results
coef(model_pcr$finalModel,10)
metrics_train<-model_pcr$results[9,2:4]
Metricas_train_PCR<-data.frame("metrics_train"="metrics_train_PCR",
                               Mean_RMSE=metrics_train$RMSE,
                               Mean_MAE=metrics_train$MAE,
                               Mean_RSquared=metrics_train$Rsquared,
                               Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))
Metricas_train_PCR
predictions_PCR<-model_pcr%>% predict(test_data)
Metricas_PCR_test<-data.frame("metrics_test"="metrics_test_PCR",
                                  RMSE=RMSE(predictions_PCR,test_data$Rate_Mort_Child),
                                  MAE=MAE(predictions_PCR,test_data$Rate_Mort_Child),
                                  RSquared=caret::R2(predictions_PCR,test_data$Rate_Mort_Child), 
                                  Tasa_Error_Test=RMSE(predictions_PCR,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))
Metricas_PCR_test


plot(varImp(model_pcr),15,main="% Importancia Variables")

```


#### SELECCIÓN DE MODELOS: REGRESIÓN DE __**MÍNIMOS CUADRADOS PARCIALES**__ (PLS)
1. La regresión de componentes principales primero aplica el "Ánalisis de componentes principales" en el conjunto de datos para resumir las variables predictoras originales en pocas variables nuevas, también conocidas como componenetes principales (PC), que son una combinación lineal de los datos originales.
2. Un inconveniente de la PCR es que no tenemos garantía de que las componentes principales seleccionados estén asociados con el resultado. La selección de componentes principales para incorporar en el modelo no está supervisada por la variable resultado.
3. Se utiliza *Cross Validation* para identificar automáticamente el número óptimo de componentes principales **ncomp**
4. Con la opción *tuneLength* probaremos 9 valores diferentes del parámetro de ajuste *ncomp*.
5. La opción *scale=TRUE* para estandarizar las variables
6. Nuestro análisis prueba que al elegir 10 componentes principales (ncomp=10) se obtiene el menor error de predicción RMSE. El 97,29% de la variación contenida en los predictores son capturados por 10 componentes principales. Además captura el 99,99% de la información de la variable resultado.
7. Se muestra gráfico con el % de Importancia de las variables.Si endo las variables por encima de un 96% las siguientes:
>.- Mort_Diarrhoeal_rate
>.- Mort_Respiratory_rate
>.- Mort_Other_rate
>.- Life_expectancy_at_birth
>.- Mort_Asphyxia_rate
>.- Mort_Meningitis_Rate
>.- Inm_MCV1_1st_coverage
>.- Inm_DTP3_coverage
>.- Maternal_Mort_Rate
>.- Inm_Pol3_coverage

```{r}
set.seed(123)
model_pls<-train(Rate_Mort_Child~., data=train_data,
                 method="pls",
                 scale=TRUE,
                 trControl=trainControl("cv",number=5),
                 tuneLength=10)
plot(model_pls,main="Componentes vs RMSE")

model_pls$bestTune
summary(model_pls)
model_pls$results
coef(model_pls$finalModel,10)
metrics_train<-model_pls$results[10,2:4]
Metricas_train_PLS<-data.frame("metrics_train"="metrics_train_PLS",
                               Mean_RMSE=metrics_train$RMSE,
                               Mean_MAE=metrics_train$MAE,
                               Mean_RSquared=metrics_train$Rsquared,
                               Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))
Metricas_train_PLS
predictions_PLS<-model_pls%>% predict(test_data)
Metricas_PLS_test<-data.frame("metrics_test"="metrics_test_PLS",
                              RMSE=RMSE(predictions_PLS,test_data$Rate_Mort_Child),
                              MAE=MAE(predictions_PLS,test_data$Rate_Mort_Child),
                              RSquared=caret::R2(predictions_PLS,test_data$Rate_Mort_Child), 
                            Tasa_Error_Test=RMSE(predictions_PLS,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))
Metricas_PLS_test


plot(varImp(model_pls),15,main="% Importancia Variables")
```






#### MACHINE LEARNING: __**K-Nearest Neighbors**__ **KNN**

```{r}
set.seed(123)
model_KNN<-train(Rate_Mort_Child~.,data=train_data,
             method="knn",
             trControl=trainControl("cv",number = 5),
             preProcess=c("center","scale"),
             metric=c("RMSE"),
             tuneLength=10)
plot(model_KNN,main="KNN vs RMSE")
model_KNN$bestTune
metrics_train<-model_KNN$results[1,2:4]
Metricas_train_KNN<-data.frame("metrics_train"="metrics_train_KNN",
                               Mean_RMSE=metrics_train$RMSE,
                               Mean_MAE=metrics_train$MAE,
                               Mean_RSquared=metrics_train$Rsquared,
                               Tasa_Error_Train=metrics_train$RMSE/mean(train_data$Rate_Mort_Child))
Metricas_train_KNN

predictions_KNN<-model_KNN %>% predict(test_data)
Metricas_KNN_test<-data.frame("metrics_test"="metrics_test_KNN",
                              RMSE=RMSE(predictions_KNN,test_data$Rate_Mort_Child),
                              MAE=MAE(predictions_KNN,test_data$Rate_Mort_Child),
                              RSquared=caret::R2(predictions_KNN,test_data$Rate_Mort_Child), 
                              Tasa_Error_Test=RMSE(predictions_KNN,test_data$Rate_Mort_Child)/mean(test_data$Rate_Mort_Child))
Metricas_KNN_test

ggplot(varImp(model_KNN),15,main="% Importancia Variables")



```

#### MACHINE LEARNING: __**RAMDOM FOREST**__ **RF**

```{r}
set.seed(123)
model_random_forest<-train(Rate_Mort_Child~.,
                           data=train_data,
                           method="rf",
                           trControl=trainControl("cv",number=5),
                           importance=TRUE)
model_random_forest$bestTune
model_random_forest$results
model_random_forest$finalModel

predictions_random_forest<-model_random_forest %>%
  predict(test_data)
RMSE(predictions_random_forest,test_data$Rate_Mort_Child)
MAE(predictions_random_forest,test_data$Rate_Mort_Child)
caret::R2(predictions_random_forest,test_data$Rate_Mort_Child)


par(mar=c(1,1,1,1))
importance(model_random_forest$finalModel)
varImpPlot(model_random_forest$finalModel,type=1) #disminución media de la precisión
varImpPlot(model_random_forest$finalModel,type=2) #disminución media de la impureza del nodo

plot(varImp(model_random_forest))

```

#### COMPARATIVA MEJORES MODELOS en "CROSS VALIDATION".
```{r}
Metricas_train<-data.frame(rbind(Metricas_train_lasso,
Metricas_train_leapForward,
Metricas_train_best_regsubsets,
Metricas_train_PLS))
Metricas_train

metricas_train_longer <- Metricas_train %>%
  pivot_longer(cols="Mean_RMSE":"Tasa_Error_Train",
               names_to="names",
               values_to = "value")
metricas_train_longer$value<-round(metricas_train_longer$value,4)

ggplot(data=metricas_train_longer,aes(x=names,y=value, fill=metrics_train))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas en Cross Validation*
          para los mejores modelos")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette=15)
```
#### COMPARATIVA MEJORES MODELOS en "TEST".
```{r}
Metricas_test<-data.frame(rbind(Metricas_lasso_test,
Metricas_leapForward_test,
Metricas_best_regsubsets_test,
Metricas_PLS_test))
Metricas_test

metricas_test_longer <- Metricas_test %>%
  pivot_longer(cols="RMSE":"Tasa_Error_Test",
               names_to="names",
               values_to = "value")
metricas_test_longer$value<-round(metricas_test_longer$value,4)

ggplot(data=metricas_test_longer,aes(x=names,y=value, fill=metrics_test))+
  geom_bar(stat="identity",position=position_dodge())+
  xlab("Métrics")+
  ylab("values")+
  geom_text(aes(label=value),position=position_dodge(width=0.9), vjust=2,size=2)+
  ggtitle("Comparativa *Métricas en TEST*
          para los mejores modelos")+
  theme(plot.title = element_text(hjust = 0.5,face="bold.italic",color="grey"))+
  scale_fill_brewer( palette=17)
```


